{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Insights\n",
   "id": "1dadbf548aedf63e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T15:14:53.976993Z",
     "start_time": "2025-11-12T15:14:53.311558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "8b8addce78c637f9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T15:14:54.815880Z",
     "start_time": "2025-11-12T15:14:54.771542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CovidDataAnalyzer.ipynb\n",
    "class CovidDataAnalyzer:\n",
    "    def __init__(self, file_path=None):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer by loading the dataset from the given file path (if there is one).\n",
    "\n",
    "        Attributes:\n",
    "            self.data: stores the full loaded dataset\n",
    "            self.filtered_data: stores filtered versions of the dataset\n",
    "\n",
    "        Parameters:\n",
    "        file_path (str): Path to the CSV file containing COVID-19 data.\n",
    "        \"\"\"\n",
    "        self.data = pd.DataFrame()\n",
    "        self.filtered_data = pd.DataFrame()\n",
    "\n",
    "        # If a path is provided at initialization, use the public method to load it.\n",
    "        if file_path:\n",
    "            if self.load_data(file_path):\n",
    "                print(f\"Data loaded successfully: {self.data.shape[0]} rows, {self.data.shape[1]} columns\")\n",
    "\n",
    "        #---------- methods for Loading, cleaning and Describing the data----------\n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the dataset from the given CSV file path into self.data.\n",
    "        This method is public and can be called externally at any time.\n",
    "\n",
    "        Parameters:\n",
    "        file_path (str): The path to the CSV file.\n",
    "\n",
    "        Returns:\n",
    "        bool: True if data loaded successfully, False otherwise.\n",
    "        \"\"\"\n",
    "       # 1. Validation\n",
    "        if not isinstance(file_path, str) or not file_path:\n",
    "            print(\"Error: file_path must be a non-empty string.\")\n",
    "            return False\n",
    "\n",
    "        # 2. Loading Logic\n",
    "        try:\n",
    "            temp_data = pd.read_csv(file_path)\n",
    "\n",
    "            # 3. Update State\n",
    "            self.data = temp_data\n",
    "            self.filtered_data = pd.DataFrame() # Reset filtered data\n",
    "\n",
    "            print(f\"Data loaded successfully: {self.data.shape[0]} rows, {self.data.shape[1]} columns\")\n",
    "            return True\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at path: {file_path}\")\n",
    "            return False\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: File at path '{file_path}' is empty.\")\n",
    "            self.data = pd.DataFrame() # Ensure data is an empty DataFrame\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during data loading: {e}\")\n",
    "            return False\n",
    "\n",
    "    def describe_data(self):\n",
    "        \"\"\"\n",
    "        Prints the shape, column names, and basic descriptive statistics\n",
    "        of the loaded dataset (self.data).\n",
    "        \"\"\"\n",
    "        if self.data is None or self.data.empty:\n",
    "            print(\"Cannot describe data: No dataset loaded or dataset is empty.\")\n",
    "            return\n",
    "\n",
    "        # Replace inf values with NaN to avoid warnings\n",
    "        self.data = self.data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"                 DATASET OVERVIEW\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # 1. Shape\n",
    "        print(\"### 1. Dataset Shape\")\n",
    "        rows, cols = self.data.shape\n",
    "        print(f\"Shape: {rows} rows, {cols} columns\")\n",
    "\n",
    "        # 2. Column Information (Names, Types, Missing Values)\n",
    "        print(\"\\n### 2. Column Information and Null Counts\")\n",
    "        self.data.info(verbose=False, memory_usage=False)\n",
    "\n",
    "        # 3. Descriptive Statistics for Numerical Columns\n",
    "        print(\"\\n### 3. Basic Descriptive Statistics (Numerical)\")\n",
    "        # Transpose the output for better readability\n",
    "        print(self.data.describe().T)\n",
    "\n",
    "        # 4. Descriptive Statistics for Categorical Columns\n",
    "        print(\"\\n### 4. Basic Descriptive Statistics (Categorical/Object)\")\n",
    "        # Include 'object' types (strings/categories)\n",
    "        print(self.data.describe(include=['object', 'category']).T)\n",
    "\n",
    "        # 5. Null values\n",
    "        print(\"\\n--- Missing Values Per Column ---\")\n",
    "        print(self.data.isnull().sum())\n",
    "\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    def handle_missing_values(self):\n",
    "        \"\"\"\n",
    "        Fills missing (NaN) values in the self.data DataFrame:\n",
    "        - Numeric columns are filled with 0.\n",
    "        - Categorical (object/string) columns are filled with \"Unknown\".\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot handle missing values: The dataset is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"         HANDLING MISSING VALUES\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # 1. Identify Numeric and Categorical Columns\n",
    "\n",
    "        # Selects columns that are numeric (int, float)\n",
    "        numeric_cols = self.data.select_dtypes(include=np.number).columns\n",
    "\n",
    "        # Selects columns that are object (string/categorical)\n",
    "        categorical_cols = self.data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "        # 2. Impute Numeric Missing Values with 0\n",
    "\n",
    "        # Use inplace=True to modify the DataFrame directly\n",
    "        self.data[numeric_cols] = self.data[numeric_cols].fillna(0)\n",
    "        print(f\"Filled missing values in {len(numeric_cols)} numeric column(s) with **0**.\")\n",
    "\n",
    "        # 3. Impute Categorical Missing Values with \"Unknown\"\n",
    "\n",
    "        # Use inplace=True to modify the DataFrame directly\n",
    "        self.data[categorical_cols] = self.data[categorical_cols].fillna(\"Unknown\")\n",
    "        print(f\"Filled missing values in {len(categorical_cols)} categorical column(s) with **'Unknown'**.\")\n",
    "\n",
    "        print(\"Missing value handling complete. Check `.info()` to verify.\")\n",
    "\n",
    "    #-------------------- methods for Filtering the data--------------------\n",
    "    def filter_high_cases(self):\n",
    "        \"\"\"\n",
    "        Filters the dataset (self.data) based on specific high-impact conditions\n",
    "        and saves the result to self.filtered_data.\n",
    "\n",
    "        Conditions:\n",
    "        - 'Confirmed_Cases' > 100,000\n",
    "        - 'Deaths' > 5,000\n",
    "        - 'Country' is not \"Unknown\"\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot filter data: The main dataset (self.data) is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"          APPLYING HIGH-CASE FILTER\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Rename required columns for filtering\n",
    "        self.data.rename(columns={\n",
    "        'Country/Region': 'Country',\n",
    "        'Confirmed': 'Confirmed_Cases'\n",
    "        }, inplace=True)\n",
    "        # Ensure required columns exist before filtering to prevent errors\n",
    "        required_cols = ['Confirmed_Cases', 'Deaths', 'Country']\n",
    "        missing_cols = [col for col in required_cols if col not in self.data.columns]\n",
    "\n",
    "        if missing_cols:\n",
    "            print(f\"Error: Cannot filter. The following required columns are missing: {', '.join(missing_cols)}\")\n",
    "            return\n",
    "\n",
    "        # 1. Define the Boolean Conditions\n",
    "        condition_cases = self.data['Confirmed_Cases'] > 100000\n",
    "        condition_deaths = self.data['Deaths'] > 5000\n",
    "        condition_country = self.data['Country'] != \"Unknown\"\n",
    "\n",
    "        combined_conditions = condition_cases & condition_deaths & condition_country\n",
    "\n",
    "        # 2. Apply the Filter and Save\n",
    "        self.filtered_data = self.data[combined_conditions].copy()\n",
    "\n",
    "        # Using .copy() is important to ensure self.filtered_data is an independent\n",
    "        # DataFrame and not just a \"view\" of self.data.\n",
    "\n",
    "        # 3. Report Results\n",
    "        original_rows = self.data.shape[0]\n",
    "        filtered_rows = self.filtered_data.shape[0]\n",
    "\n",
    "        print(f\"Original dataset size: {original_rows} rows\")\n",
    "        print(f\"Filtered dataset size: {filtered_rows} rows\")\n",
    "        print(f\"Filtered data saved successfully to **self.filtered_data**.\")\n",
    "\n",
    "        return self.filtered_data\n",
    "\n",
    "    def filter_by_date_range(self, start_date, end_date, date_column='Date'):\n",
    "        \"\"\"\n",
    "        Filters the dataset (self.data) for records falling within the\n",
    "        specified start_date and end_date range (inclusive).\n",
    "\n",
    "        Parameters:\n",
    "        start_date (str): The starting date for the filter (e.g., '2020-03-01').\n",
    "        end_date (str): The ending date for the filter (e.g., '2020-04-30').\n",
    "        date_column (str): The name of the date column in self.data (default 'Date').\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot filter data: The main dataset (self.data) is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        if date_column not in self.data.columns:\n",
    "            print(f\"Error: Date column '{date_column}' not found in the dataset.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"          APPLYING DATE RANGE FILTER\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        try:\n",
    "            # 1. Convert Input Strings to Datetime Objects\n",
    "            # This is crucial for accurate comparison.\n",
    "            start_dt = pd.to_datetime(start_date)\n",
    "            end_dt = pd.to_datetime(end_date)\n",
    "\n",
    "            # 2. Ensure the DataFrame Column is Datetime\n",
    "            # Convert the specified column to datetime format in place\n",
    "            self.data[date_column] = pd.to_datetime(self.data[date_column])\n",
    "\n",
    "            # 3. Define and Apply the Boolean Condition (Inclusive Range)\n",
    "            # The filter includes both the start date and the end date.\n",
    "            condition = (self.data[date_column] >= start_dt) & \\\n",
    "                        (self.data[date_column] <= end_dt)\n",
    "\n",
    "            # 4. Apply the Filter and Save\n",
    "            self.filtered_data = self.data[condition].copy()\n",
    "\n",
    "            # 5. Report Results\n",
    "            original_rows = self.data.shape[0]\n",
    "            filtered_rows = self.filtered_data.shape[0]\n",
    "\n",
    "            print(f\"Filtering data from {start_date} to {end_date}...\")\n",
    "            print(f\"Original dataset size: {original_rows} rows\")\n",
    "            print(f\"Filtered dataset size: {filtered_rows} rows\")\n",
    "            print(f\"âœ… Filtered data saved successfully to **self.filtered_data**.\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Failed to convert date strings. Check if '{start_date}' or '{end_date}' are in a valid date format. Details: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during date filtering: {e}\")\n",
    "\n",
    "        return self.filtered_data\n",
    "\n",
    "    #--------------------  G  L  O  B  A  L ---- S  T  A  T  I  S  T  I  C  S--------------------\n",
    "    def calculate_global_statistics(self):\n",
    "        \"\"\"\n",
    "        Calculates the global total for Confirmed, Deaths, and Recovered\n",
    "        cases across the entire dataset (self.data) and prints the results.\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot calculate global statistics: The dataset is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        # Define the columns  needed to check and sum\n",
    "        stats_cols = ['Confirmed_Cases', 'Deaths', 'Recovered']\n",
    "\n",
    "        # Check if all required columns exist\n",
    "        missing_cols = [col for col in stats_cols if col not in self.data.columns]\n",
    "\n",
    "        if missing_cols:\n",
    "            print(f\"Error: Cannot calculate statistics. Missing required columns: {', '.join(missing_cols)}\")\n",
    "            # Attempt to proceed with only the columns that are present\n",
    "            stats_cols = [col for col in stats_cols if col not in missing_cols]\n",
    "            if not stats_cols:\n",
    "                return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"          GLOBAL CASE STATISTICS\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        try:\n",
    "            # Calculate the sum for the desired columns.\n",
    "            # .sum() will ignore any NaN values by default.\n",
    "            global_totals = self.data[stats_cols].sum(numeric_only=True)\n",
    "\n",
    "            # Format and Print Results\n",
    "            print(f\"Global Total Confirmed Cases: {int(global_totals.get('Confirmed_Cases', 0)):,}\")\n",
    "            print(f\"Global Total Deaths:          {int(global_totals.get('Deaths', 0)):,}\")\n",
    "            print(f\"Global Total Recovered Cases: {int(global_totals.get('Recovered', 0)):,}\")\n",
    "            print(\"âœ… Global statistics calculated and printed.\")\n",
    "\n",
    "        except TypeError:\n",
    "            print(\"Error: One or more required columns are not numeric (e.g., 'Confirmed_Cases'). Ensure data types are correct.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    #--------------------  utility ----  methods--------------------\n",
    "    def save_filtered_data(self, filename):\n",
    "        \"\"\"\n",
    "        Saves the current self.filtered_data DataFrame to a specified CSV file.\n",
    "\n",
    "        Parameters:\n",
    "        filename (str): The name and path of the file to save the data to.\n",
    "        \"\"\"\n",
    "        if self.filtered_data.empty:\n",
    "            print(\"â— Cannot save data: self.filtered_data is empty. Apply a filter first.\")\n",
    "            return\n",
    "\n",
    "        if not isinstance(filename, str) or not filename.endswith('.csv'):\n",
    "            print(\"ðŸ›‘ Error: Filename must be a string and end with '.csv'.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"          SAVING FILTERED DATA\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        try:\n",
    "            # Save the DataFrame to the specified CSV file.\n",
    "            # index=False prevents pandas from writing the DataFrame's row indices\n",
    "            # as an extra, unnecessary column in the CSV file.\n",
    "            self.filtered_data.to_csv(filename, index=False)\n",
    "\n",
    "            rows = self.filtered_data.shape[0]\n",
    "            print(f\"âœ… Successfully saved **{rows} rows** to **{filename}**.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ðŸ›‘ An error occurred during file saving: {e}\")\n",
    "\n",
    "    def reset_filtered_data(self):\n",
    "        \"\"\"\n",
    "        Resets the self.filtered_data DataFrame to an empty DataFrame.\n",
    "        \"\"\"\n",
    "        self.filtered_data = pd.DataFrame()\n",
    "        print(\"Filtered_data has been reset.\")\n",
    "\n",
    "    def generate_insights(self):\n",
    "        \"\"\"\n",
    "        Automatically prints readable insights from the loaded dataset:\n",
    "        - Number of countries\n",
    "        - Country with highest & lowest confirmed cases\n",
    "        - Average confirmed cases\n",
    "        - Death rate statistics (if available)\n",
    "        - Missing value summary\n",
    "        \"\"\"\n",
    "\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot generate insights: Dataset is empty.\")\n",
    "            return\n",
    "\n",
    "        required_columns = ['Country', 'Confirmed_Cases']\n",
    "\n",
    "        if not all(col in self.data.columns for col in required_columns):\n",
    "            print(\"Cannot generate insights: Dataset must contain 'Country' and 'Confirmed_Cases'.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*55)\n",
    "        print(\"                 AUTOMATED DATA INSIGHTS\")\n",
    "        print(\"=\"*55)\n",
    "\n",
    "        # 1. Number of countries\n",
    "        total_countries = self.data['Country'].nunique()\n",
    "        print(f\"There are {total_countries} countries in the dataset.\")\n",
    "\n",
    "        # 2. Highest and lowest confirmed cases\n",
    "        max_row = self.data.loc[self.data['Confirmed_Cases'].idxmax()]\n",
    "        min_row = self.data.loc[self.data['Confirmed_Cases'].idxmin()]\n",
    "\n",
    "        print(f\"The country with the highest confirmed cases is {max_row['Country']} \"\n",
    "              f\"with {max_row['Confirmed_Cases']:,} cases.\")\n",
    "\n",
    "        print(f\"The country with the lowest confirmed cases is {min_row['Country']} \"\n",
    "              f\"with {min_row['Confirmed_Cases']:,} cases.\")\n",
    "\n",
    "        # 3. Average confirmed cases\n",
    "        avg_cases = self.data['Confirmed_Cases'].mean()\n",
    "        print(f\"On average, countries reported about {avg_cases:,.0f} confirmed cases.\")\n",
    "\n",
    "        # 4. Death rate (if deaths exist)\n",
    "        if 'Deaths' in self.data.columns and self.data['Deaths'].sum() > 0:\n",
    "            total_cases = self.data['Confirmed_Cases'].sum()\n",
    "            total_deaths = self.data['Deaths'].sum()\n",
    "            death_rate = (total_deaths / total_cases) * 100\n",
    "\n",
    "            print(f\"The overall global death rate is approximately {death_rate:.2f}% \"\n",
    "                  f\"({total_deaths:,} deaths out of {total_cases:,} confirmed cases).\")\n",
    "        else:\n",
    "            print(\"Death statistics are not available in this dataset.\")\n",
    "\n",
    "        # 5. Missing value summary\n",
    "        missing = self.data.isnull().sum()\n",
    "        missing = missing[missing > 0]  # Only show columns with missing data\n",
    "\n",
    "        if not missing.empty:\n",
    "            print(\"\\nSome columns contain missing values:\")\n",
    "            for col, count in missing.items():\n",
    "                print(f\" - {col}: {count} missing entries\")\n",
    "        else:\n",
    "            print(\"No missing values detected in the dataset.\")\n",
    "\n",
    "        print(\"=\"*55)\n"
   ],
   "id": "2bf06121cc0dfc5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T15:15:02.480724Z",
     "start_time": "2025-11-12T15:15:02.306859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Initialize the class with covid_data.csv.\n",
    "analyzer = CovidDataAnalyzer()\n",
    "analyzer.load_data('datasets/covid_19_data.csv')\n",
    "# analyzer.load_data('datasets/covid_19_clean_complete.csv')\n",
    "\n",
    "# 2. Load and describe the dataset.\n",
    "analyzer.describe_data()\n",
    "\n",
    "# 3. Handle missing values.\n",
    "analyzer.handle_missing_values()\n",
    "\n",
    "# 4. Apply the filter_high_cases method and save the filtered data.\n",
    "analyzer.filter_high_cases()\n",
    "\n",
    "# 5. Apply the filter_by_date_range method for a specific range (e.g., March 2020 to June 2020) and save the filtered data.\n",
    "# analyzer.load_data('datasets/day_wise.csv')\n",
    "# analyzer.filter_by_date_range('2020-03-01', '2020-06-30')\n",
    "\n",
    "# 6. Calculate and display global statistics.\n",
    "analyzer.calculate_global_statistics()\n",
    "\n",
    "# 7. Provide insights\n",
    "analyzer.generate_insights()\n",
    "\n",
    "# 8. Test save a file\n",
    "analyzer.save_filtered_data(\"datasets/high_impact_covid_data.csv\")"
   ],
   "id": "d9ddf47700597b5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully: 49068 rows, 10 columns\n",
      "\n",
      "==================================================\n",
      "                 DATASET OVERVIEW\n",
      "==================================================\n",
      "### 1. Dataset Shape\n",
      "Shape: 49068 rows, 10 columns\n",
      "\n",
      "### 2. Column Information and Null Counts\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49068 entries, 0 to 49067\n",
      "Columns: 10 entries, Province/State to WHO Region\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "### 3. Basic Descriptive Statistics (Numerical)\n",
      "             count          mean            std       min        25%  \\\n",
      "Lat        49068.0     21.433730      24.950320  -51.7963   7.873054   \n",
      "Long       49068.0     23.528236      70.442740 -135.0000 -15.310100   \n",
      "Confirmed  49068.0  16884.904255  127300.205272    0.0000   4.000000   \n",
      "Deaths     49068.0    884.179160    6313.584411    0.0000   0.000000   \n",
      "Recovered  49068.0   7915.713479   54800.918731    0.0000   0.000000   \n",
      "Active     49068.0   8085.011617   76258.903026  -14.0000   0.000000   \n",
      "\n",
      "                50%          75%           max  \n",
      "Lat         23.6345    41.204380  7.170690e+01  \n",
      "Long        21.7453    80.771797  1.780650e+02  \n",
      "Confirmed  168.0000  1518.250000  4.290259e+06  \n",
      "Deaths       2.0000    30.000000  1.480110e+05  \n",
      "Recovered   29.0000   666.000000  1.846641e+06  \n",
      "Active      26.0000   606.000000  2.816444e+06  \n",
      "\n",
      "### 4. Basic Descriptive Statistics (Categorical/Object)\n",
      "                count unique                           top   freq\n",
      "Province/State  14664     78  Australian Capital Territory    188\n",
      "Country/Region  49068    187                         China   6204\n",
      "Date            49068    188                    2020-01-22    261\n",
      "WHO Region      49068      6                        Europe  15040\n",
      "\n",
      "--- Missing Values Per Column ---\n",
      "Province/State    34404\n",
      "Country/Region        0\n",
      "Lat                   0\n",
      "Long                  0\n",
      "Date                  0\n",
      "Confirmed             0\n",
      "Deaths                0\n",
      "Recovered             0\n",
      "Active                0\n",
      "WHO Region            0\n",
      "dtype: int64\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "          APPLYING HIGH-CASE FILTER\n",
      "==================================================\n",
      "Original dataset size: 49068 rows\n",
      "Filtered dataset size: 1172 rows\n",
      "Filtered data saved successfully to **self.filtered_data**.\n",
      "\n",
      "=======================================================\n",
      "                 AUTOMATED DATA INSIGHTS\n",
      "=======================================================\n",
      "There are 187 countries in the dataset.\n",
      "The country with the highest confirmed cases is US with 4,290,259 cases.\n",
      "The country with the lowest confirmed cases is Afghanistan with 0 cases.\n",
      "On average, countries reported about 16,885 confirmed cases.\n",
      "The overall global death rate is approximately 5.24% (43,384,903 deaths out of 828,508,482 confirmed cases).\n",
      "\n",
      "Some columns contain missing values:\n",
      " - Province/State: 34404 missing entries\n",
      "=======================================================\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e8d2517b3fe712ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
