{
 "cells": [
  {
   "cell_type": "code",
   "id": "5d2cfcaf-763f-4e7d-9dcc-9e69911ed2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:53:54.291062Z",
     "start_time": "2025-11-10T18:53:53.285726Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:53:54.351764Z",
     "start_time": "2025-11-10T18:53:54.316714Z"
    }
   },
   "source": [
    "# CovidDataAnalyzer.ipynb\n",
    "class CovidDataAnalyzer:\n",
    "    def __init__(self, file_path=None):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer by loading the dataset from the given file path (if there is one).\n",
    "\n",
    "        Attributes:\n",
    "            self.data: stores the full loaded dataset\n",
    "            self.filtered_data: stores filtered versions of the dataset\n",
    "            \n",
    "        Parameters:\n",
    "        file_path (str): Path to the CSV file containing COVID-19 data.\n",
    "        \"\"\"       \n",
    "        self.data = pd.DataFrame()\n",
    "        self.filtered_data = pd.DataFrame()\n",
    "\n",
    "        # If a path is provided at initialization, use the public method to load it.\n",
    "        if file_path:\n",
    "            if self.load_data(file_path):\n",
    "                print(f\"Data loaded successfully: {self.data.shape[0]} rows, {self.data.shape[1]} columns\")\n",
    "\n",
    "        #---------- methods for Loading, cleaning and Describing the data----------\n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the dataset from the given CSV file path into self.data.\n",
    "        This method is public and can be called externally at any time.\n",
    "        \n",
    "        Parameters:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        \n",
    "        Returns:\n",
    "        bool: True if data loaded successfully, False otherwise.\n",
    "        \"\"\"\n",
    "       # 1. Validation\n",
    "        if not isinstance(file_path, str) or not file_path:\n",
    "            print(\"Error: file_path must be a non-empty string.\")\n",
    "            return False\n",
    "\n",
    "        # 2. Loading Logic\n",
    "        try:\n",
    "            temp_data = pd.read_csv(file_path)\n",
    "            \n",
    "            # 3. Update State\n",
    "            self.data = temp_data\n",
    "            self.filtered_data = pd.DataFrame() # Reset filtered data\n",
    "            \n",
    "            print(f\"Data loaded successfully: {self.data.shape[0]} rows, {self.data.shape[1]} columns\")\n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at path: {file_path}\")\n",
    "            return False\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: File at path '{file_path}' is empty.\")\n",
    "            self.data = pd.DataFrame() # Ensure data is an empty DataFrame\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during data loading: {e}\")\n",
    "            return False\n",
    "\n",
    "    def describe_data(self):\n",
    "        \"\"\"\n",
    "        Prints the shape, column names, and basic descriptive statistics \n",
    "        of the loaded dataset (self.data).\n",
    "        \"\"\"\n",
    "        if self.data is None or self.data.empty:\n",
    "            print(\"Cannot describe data: No dataset loaded or dataset is empty.\")\n",
    "            return\n",
    "\n",
    "        # Replace inf values with NaN to avoid warnings\n",
    "        # self.data = self.data.replace([float('inf'), -float('inf')], pd.NA)\n",
    "        self.data = self.data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"                 DATASET OVERVIEW\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # 1. Shape\n",
    "        print(\"### 1. Dataset Shape\")\n",
    "        rows, cols = self.data.shape\n",
    "        print(f\"Shape: {rows} rows, {cols} columns\")\n",
    "\n",
    "        # 2. Column Information (Names, Types, Missing Values)\n",
    "        print(\"\\n### 2. Column Information and Null Counts\")\n",
    "        self.data.info(verbose=False, memory_usage=False)\n",
    "        \n",
    "        # 3. Descriptive Statistics for Numerical Columns\n",
    "        print(\"\\n### 3. Basic Descriptive Statistics (Numerical)\")\n",
    "        # Transpose the output for better readability\n",
    "        print(self.data.describe().T) \n",
    "\n",
    "        # 4. Descriptive Statistics for Categorical Columns\n",
    "        print(\"\\n### 4. Basic Descriptive Statistics (Categorical/Object)\")\n",
    "        # Include 'object' types (strings/categories)\n",
    "        print(self.data.describe(include=['object', 'category']).T) \n",
    "        \n",
    "        print(\"=\"*50)\n",
    "\n",
    "    def handle_missing_values(self):\n",
    "        \"\"\"\n",
    "        Fills missing (NaN) values in the self.data DataFrame:\n",
    "        - Numeric columns are filled with 0.\n",
    "        - Categorical (object/string) columns are filled with \"Unknown\".\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot handle missing values: The dataset is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"         HANDLING MISSING VALUES\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # 1. Identify Numeric and Categorical Columns\n",
    "        \n",
    "        # Selects columns that are numeric (int, float)\n",
    "        numeric_cols = self.data.select_dtypes(include=np.number).columns\n",
    "        \n",
    "        # Selects columns that are object (string/categorical)\n",
    "        categorical_cols = self.data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "        # 2. Impute Numeric Missing Values with 0\n",
    "        \n",
    "        # Use inplace=True to modify the DataFrame directly\n",
    "        self.data[numeric_cols] = self.data[numeric_cols].fillna(0)\n",
    "        print(f\"Filled missing values in {len(numeric_cols)} numeric column(s) with **0**.\")\n",
    "\n",
    "        # 3. Impute Categorical Missing Values with \"Unknown\"\n",
    "        \n",
    "        # Use inplace=True to modify the DataFrame directly\n",
    "        self.data[categorical_cols] = self.data[categorical_cols].fillna(\"Unknown\")\n",
    "        print(f\"Filled missing values in {len(categorical_cols)} categorical column(s) with **'Unknown'**.\")\n",
    "        \n",
    "        print(\"Missing value handling complete. Check `.info()` to verify.\")\n",
    "\n",
    "    #-------------------- methods for Filtering the data--------------------\n",
    "    def filter_high_cases(self):\n",
    "        \"\"\"\n",
    "        Filters the dataset (self.data) based on specific high-impact conditions\n",
    "        and saves the result to self.filtered_data.\n",
    "\n",
    "        Conditions:\n",
    "        - 'Confirmed_Cases' > 100,000\n",
    "        - 'Deaths' > 5,000\n",
    "        - 'Country' is not \"Unknown\"\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot filter data: The main dataset (self.data) is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"          APPLYING HIGH-CASE FILTER\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Ensure required columns exist before filtering to prevent errors\n",
    "        required_cols = ['Confirmed_Cases', 'Deaths', 'Country']\n",
    "        missing_cols = [col for col in required_cols if col not in self.data.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"Error: Cannot filter. The following required columns are missing: {', '.join(missing_cols)}\")\n",
    "            return\n",
    "            \n",
    "        # 1. Define the Boolean Conditions\n",
    "        condition_cases = self.data['Confirmed_Cases'] > 100000\n",
    "        condition_deaths = self.data['Deaths'] > 5000\n",
    "        condition_country = self.data['Country'] != \"Unknown\"\n",
    "        \n",
    "        combined_conditions = condition_cases & condition_deaths & condition_country\n",
    "        \n",
    "        # 2. Apply the Filter and Save\n",
    "        self.filtered_data = self.data[combined_conditions].copy()\n",
    "        \n",
    "        # Using .copy() is important to ensure self.filtered_data is an independent \n",
    "        # DataFrame and not just a \"view\" of self.data.\n",
    "        \n",
    "        # 3. Report Results\n",
    "        original_rows = self.data.shape[0]\n",
    "        filtered_rows = self.filtered_data.shape[0]\n",
    "        \n",
    "        print(f\"Original dataset size: {original_rows} rows\")\n",
    "        print(f\"Filtered dataset size: {filtered_rows} rows\")\n",
    "        print(f\"Filtered data saved successfully to **self.filtered_data**.\")\n",
    "\n",
    "    def filter_by_date_range(self, start_date, end_date, date_column='Date'):\n",
    "        \"\"\"\n",
    "        Filters the dataset (self.data) for records falling within the \n",
    "        specified start_date and end_date range (inclusive).\n",
    "\n",
    "        Parameters:\n",
    "        start_date (str): The starting date for the filter (e.g., '2020-03-01').\n",
    "        end_date (str): The ending date for the filter (e.g., '2020-04-30').\n",
    "        date_column (str): The name of the date column in self.data (default 'Date').\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot filter data: The main dataset (self.data) is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        if date_column not in self.data.columns:\n",
    "            print(f\"Error: Date column '{date_column}' not found in the dataset.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"          APPLYING DATE RANGE FILTER\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        try:\n",
    "            # 1. Convert Input Strings to Datetime Objects\n",
    "            # This is crucial for accurate comparison.\n",
    "            start_dt = pd.to_datetime(start_date)\n",
    "            end_dt = pd.to_datetime(end_date)\n",
    "            \n",
    "            # 2. Ensure the DataFrame Column is Datetime\n",
    "            # Convert the specified column to datetime format in place\n",
    "            self.data[date_column] = pd.to_datetime(self.data[date_column])\n",
    "            \n",
    "            # 3. Define and Apply the Boolean Condition (Inclusive Range)\n",
    "            # The filter includes both the start date and the end date.\n",
    "            condition = (self.data[date_column] >= start_dt) & \\\n",
    "                        (self.data[date_column] <= end_dt)\n",
    "            \n",
    "            # 4. Apply the Filter and Save\n",
    "            self.filtered_data = self.data[condition].copy()\n",
    "            \n",
    "            # 5. Report Results\n",
    "            original_rows = self.data.shape[0]\n",
    "            filtered_rows = self.filtered_data.shape[0]\n",
    "            \n",
    "            print(f\"Filtering data from {start_date} to {end_date}...\")\n",
    "            print(f\"Original dataset size: {original_rows} rows\")\n",
    "            print(f\"Filtered dataset size: {filtered_rows} rows\")\n",
    "            print(f\"‚úÖ Filtered data saved successfully to **self.filtered_data**.\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Failed to convert date strings. Check if '{start_date}' or '{end_date}' are in a valid date format. Details: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during date filtering: {e}\")\n",
    "\n",
    "    #--------------------  G  L  O  B  A  L ---- S  T  A  T  I  S  T  I  C  S--------------------\n",
    "    def calculate_global_statistics(self):\n",
    "        \"\"\"\n",
    "        Calculates the global total for Confirmed, Deaths, and Recovered \n",
    "        cases across the entire dataset (self.data) and prints the results.\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            print(\"Cannot calculate global statistics: The dataset is empty. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        # Define the columns  needed to check and sum\n",
    "        stats_cols = ['Confirmed_Cases', 'Deaths', 'Recovered']\n",
    "        \n",
    "        # Check if all required columns exist\n",
    "        missing_cols = [col for col in stats_cols if col not in self.data.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"Error: Cannot calculate statistics. Missing required columns: {', '.join(missing_cols)}\")\n",
    "            # Attempt to proceed with only the columns that are present\n",
    "            stats_cols = [col for col in stats_cols if col not in missing_cols]\n",
    "            if not stats_cols:\n",
    "                return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"          GLOBAL CASE STATISTICS\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        try:\n",
    "            # Calculate the sum for the desired columns.\n",
    "            # .sum() will ignore any NaN values by default.\n",
    "            global_totals = self.data[stats_cols].sum(numeric_only=True)\n",
    "\n",
    "            # Format and Print Results\n",
    "            print(f\"Global Total Confirmed Cases: {int(global_totals.get('Confirmed_Cases', 0)):,}\")\n",
    "            print(f\"Global Total Deaths:          {int(global_totals.get('Deaths', 0)):,}\")\n",
    "            print(f\"Global Total Recovered Cases: {int(global_totals.get('Recovered', 0)):,}\")\n",
    "            print(\"‚úÖ Global statistics calculated and printed.\")\n",
    "\n",
    "        except TypeError:\n",
    "            print(\"Error: One or more required columns are not numeric (e.g., 'Confirmed_Cases'). Ensure data types are correct.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    #--------------------  utility ----  methods--------------------\n",
    "    def save_filtered_data(self, filename):\n",
    "        \"\"\"\n",
    "        Saves the current self.filtered_data DataFrame to a specified CSV file.\n",
    "\n",
    "        Parameters:\n",
    "        filename (str): The name and path of the file to save the data to.\n",
    "        \"\"\"\n",
    "        if self.filtered_data.empty:\n",
    "            print(\"‚ùó Cannot save data: self.filtered_data is empty. Apply a filter first.\")\n",
    "            return\n",
    "        \n",
    "        if not isinstance(filename, str) or not filename.endswith('.csv'):\n",
    "            print(\"üõë Error: Filename must be a string and end with '.csv'.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"          SAVING FILTERED DATA\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        try:\n",
    "            # Save the DataFrame to the specified CSV file.\n",
    "            # index=False prevents pandas from writing the DataFrame's row indices \n",
    "            # as an extra, unnecessary column in the CSV file.\n",
    "            self.filtered_data.to_csv(filename, index=False)\n",
    "            \n",
    "            rows = self.filtered_data.shape[0]\n",
    "            print(f\"‚úÖ Successfully saved **{rows} rows** to **{filename}**.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üõë An error occurred during file saving: {e}\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "16c97613-2134-4525-94c0-9d83f9783bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:53:54.449343Z",
     "start_time": "2025-11-10T18:53:54.366780Z"
    }
   },
   "source": [
    "# 1. Initialize the class with covid_data.csv.\n",
    "analyzer = CovidDataAnalyzer()\n",
    "analyzer.load_data('datasets/country_wise_latest.csv')\n",
    "\n",
    "# 2. Load and describe the dataset.\n",
    "analyzer.describe_data()\n",
    "\n",
    "# 3. Handle missing values.\n",
    "analyzer.handle_missing_values()\n",
    "\n",
    "# 4. Apply the filter_high_cases method and save the filtered data.\n",
    "# analyzer.filter_high_cases()\n",
    "\n",
    "# 5. Apply the filter_by_date_range method for a specific range (e.g., March 2020 to June 2020) and save the filtered data.\n",
    "# analyzer.load_data('datasets/day_wise.csv')\n",
    "# analyzer.filter_by_date_range('2020-03-01', '2020-06-30')\n",
    "\n",
    "# 6. Calculate and display global statistics.\n",
    "# analyzer.calculate_global_statistics()\n",
    "\n",
    "# 7. Test save a file\n",
    "analyzer.save_filtered_data(\"datasets/high_impact_covid_data.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully: 0 rows, 0 columns\n",
      "Data loaded successfully: 187 rows, 15 columns\n",
      "\n",
      "==================================================\n",
      "                 DATASET OVERVIEW\n",
      "==================================================\n",
      "### 1. Dataset Shape\n",
      "Shape: 187 rows, 15 columns\n",
      "\n",
      "### 2. Column Information and Null Counts\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187 entries, 0 to 186\n",
      "Columns: 15 entries, Country/Region to WHO Region\n",
      "dtypes: float64(3), int64(9), object(3)None\n",
      "\n",
      "### 3. Basic Descriptive Statistics (Numerical)\n",
      "                       count          mean            std    min       25%  \\\n",
      "Confirmed              187.0  88130.935829  383318.663831  10.00  1114.000   \n",
      "Deaths                 187.0   3497.518717   14100.002482   0.00    18.500   \n",
      "Recovered              187.0  50631.481283  190188.189643   0.00   626.500   \n",
      "Active                 187.0  34001.935829  213326.173371   0.00   141.500   \n",
      "New cases              187.0   1222.957219    5710.374790   0.00     4.000   \n",
      "New deaths             187.0     28.957219     120.037173   0.00     0.000   \n",
      "New recovered          187.0    933.812834    4197.719635   0.00     0.000   \n",
      "Deaths / 100 Cases     187.0      3.019519       3.454302   0.00     0.945   \n",
      "Recovered / 100 Cases  187.0     64.820535      26.287694   0.00    48.770   \n",
      "Confirmed last week    187.0  78682.475936  338273.676567  10.00  1051.500   \n",
      "1 week change          187.0   9448.459893   47491.127684 -47.00    49.000   \n",
      "1 week % increase      187.0     13.606203      24.509838  -3.84     2.775   \n",
      "\n",
      "                           50%        75%         max  \n",
      "Confirmed              5059.00  40460.500  4290259.00  \n",
      "Deaths                  108.00    734.000   148011.00  \n",
      "Recovered              2815.00  22606.000  1846641.00  \n",
      "Active                 1600.00   9149.000  2816444.00  \n",
      "New cases                49.00    419.500    56336.00  \n",
      "New deaths                1.00      6.000     1076.00  \n",
      "New recovered            22.00    221.000    33728.00  \n",
      "Deaths / 100 Cases        2.15      3.875       28.56  \n",
      "Recovered / 100 Cases    71.32     86.885      100.00  \n",
      "Confirmed last week    5020.00  37080.500  3834677.00  \n",
      "1 week change           432.00   3172.000   455582.00  \n",
      "1 week % increase         6.89     16.855      226.32  \n",
      "\n",
      "### 4. Basic Descriptive Statistics (Categorical/Object)\n",
      "                        count unique          top  freq\n",
      "Country/Region            187    187  Afghanistan     1\n",
      "Deaths / 100 Recovered  182.0  154.0          0.0  17.0\n",
      "WHO Region                187      6       Europe    56\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "         HANDLING MISSING VALUES\n",
      "==================================================\n",
      "Filled missing values in 12 numeric column(s) with **0**.\n",
      "Filled missing values in 3 categorical column(s) with **'Unknown'**.\n",
      "Missing value handling complete. Check `.info()` to verify.\n",
      "‚ùó Cannot save data: self.filtered_data is empty. Apply a filter first.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da27637-111d-4004-b775-56a096d84032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
